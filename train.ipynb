{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Assignment 5: CRNN For Text Recognition<br>\n", "Course Coordinator: Dr. Manojkumar Ramteke<br>\n", "Teaching Assistant: Abdur Rahman<br>\n", "This code is for educational purposes only. Unauthorized copying or distribution without the consent of the course coordinator is prohibited.<br>\n", "Copyright \u00a9 2024. All rights reserved.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import time\n", "import argparse"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import time\n", "import torch.utils.data\n", "import torch.optim as optim\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from model import Model\n", "from test import validation\n", "from dataset import  AlignCollate, Num10kDataset\n", "from utils import ConverterForCTC"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train(args, device):\n", "    args.device = device\n", "    print('\\n'+'-' * 80)\n", "    print('Device : {}'.format(device))\n", "    print('-' * 80 + '\\n')\n", "    \n", "    align_collate_function = AlignCollate(imgH=args.imgH, imgW=args.imgW, input_channel=args.input_channel)\n", "    train_dataset = Num10kDataset(args.train_data)\n", "    print(\"Loaded Train Dataset, Length: \", len(train_dataset))\n", "    valid_dataset = Num10kDataset(args.valid_data)\n", "    print(\"Loaded Validation Dataset, Length: \", len(valid_dataset))\n", "    \n", "    train_loader = torch.utils.data.DataLoader(\n", "        train_dataset, batch_size=args.batch_size,\n", "        shuffle=True,\n", "        collate_fn=align_collate_function)\n", "    valid_loader = torch.utils.data.DataLoader(\n", "        valid_dataset, batch_size=args.batch_size,\n", "        shuffle=True,\n", "        collate_fn=align_collate_function)\n", "    \n", "    # To-do: Create an instance of the ConverterForCTC\n", "        # Use the args.character to initialize the ConverterForCTC\n", "        # Set the number of classes in the args using the length of the character in the converter\n", "    \n", "    # To-do: Create an instance of the Model\n", "        # Use the args to initialize the Model\n", "        # Print the number of trainable parameters in the model\n", "        # Move the model to the device\n", "    \n", "    # To-do: Define the loss function using torch.nn.CTCLoss\n", "        # Set the blank label to 0\n", "        # Set the reduction to 'mean'\n\n", "    # To-do: Define the optimizer\n", "    \n", "    init_time = time.time()\n", "    # To-do: Write the training loop\n", "        # Iterate over the training data\n", "        # Pass the image to the model\n", "        # Encode the labels using the converter\n", "        # Calculate the loss using the criterion\n", "        # Backpropagate the loss and model parameters\n", "        # Evaluate the model on the validation dataset\n", "        # Print the training and validation loss and accuracy\n", "        # Save the best model based on the validation loss\n", "        # Plot the loss curve (Both training and validation loss)\n", "    \n", "    end_time = time.time()\n", "    print(\"Total time taken for training: \" + str(end_time-init_time))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    parser = argparse.ArgumentParser()\n", "    parser.add_argument('--output_dir', type=str, default='saved_models', help='path to save model')\n", "    parser.add_argument('--train_data', required=True, help='path to training dataset')\n", "    parser.add_argument('--valid_data', required=True, help='path to validation dataset')\n", "    parser.add_argument('--batch_size', type=int, default=32, help='input batch size')\n", "    parser.add_argument('--num_epochs', type=int, default=10, help='Number of epochs to train for')\n", "    parser.add_argument('--lr', type=float, default=1.0, help='learning rate')\n", "    parser.add_argument('--batch_max_length', type=int, default=0, help='Maximum label length') # DECIDE APPROPRIATELY BY OBSERVING THE DATASET\n", "    parser.add_argument('--imgH', type=int, default=0, help='the height of the input image') # DECIDE APPROPRIATELY BY OBSERVING THE DATASET\n", "    parser.add_argument('--imgW', type=int, default=0, help='the width of the input image') # DECIDE APPROPRIATELY BY OBSERVING THE DATASET\n", "    \n", "    \"\"\" Model Architecture - DO NOT CHANGE \"\"\"\n", "    parser.add_argument('--input_channel', type=int, default=1,\n", "                        help='the number of input channel for CNN')\n", "    parser.add_argument('--output_channel', type=int, default=512,\n", "                        help='the number of output channel for CNN')\n", "    parser.add_argument('--hidden_size', type=int, default=256, help='the size of the LSTM hidden state')\n", "    \n", "    args = parser.parse_args()\n", "    os.makedirs(args.output_dir, exist_ok=True)\n", "    \"\"\" vocab / character number configuration \"\"\"\n", "    args.character = \"0123456789\"\n", "    \n", "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "    print(\"Device : \", device)\n", "    \n", "    train(args, device)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}